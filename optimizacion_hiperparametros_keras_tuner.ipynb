{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e0ce59",
   "metadata": {},
   "source": [
    "üìö Introducci√≥n Te√≥rica\n",
    "¬øQu√© son los Hiperpar√°metros?\n",
    "Los hiperpar√°metros son configuraciones que definen la arquitectura y el comportamiento de un modelo de aprendizaje autom√°tico, pero que no se aprenden durante el entrenamiento. A diferencia de los par√°metros (como pesos y sesgos), los hiperpar√°metros deben ser establecidos antes del entrenamiento.\n",
    "\n",
    "üîç Diferencias Clave: Par√°metros vs Hiperpar√°metros\n",
    "Aspecto\tPar√°metros\tHiperpar√°metros\n",
    "Definici√≥n\tVariables aprendidas por el modelo\tConfiguraciones establecidas antes del entrenamiento\n",
    "Ejemplos\tPesos, sesgos\tLearning rate, n√∫mero de capas, dropout rate\n",
    "Optimizaci√≥n\tGradient descent, backpropagation\tGrid search, random search, Bayesian optimization\n",
    "Modificaci√≥n\tDurante el entrenamiento\tAntes del entrenamiento\n",
    "\n",
    "‚ö†Ô∏è Importancia de la Optimizaci√≥n de Hiperpar√°metros\n",
    "Rendimiento: Puede mejorar la precisi√≥n del modelo en 5-15%\n",
    "Generalizaci√≥n: Reduce overfitting y mejora la capacidad de generalizaci√≥n\n",
    "Eficiencia: Optimiza el tiempo de entrenamiento y los recursos computacionales\n",
    "Robustez: Hace el modelo m√°s estable ante variaciones en los datos\n",
    "\n",
    "üõ†Ô∏è M√©todos Tradicionales vs Keras Tuner\n",
    "M√©todos Tradicionales:\n",
    "\n",
    "Manual: Ajuste basado en experiencia e intuici√≥n\n",
    "Grid Search: B√∫squeda exhaustiva en una grilla predefinida\n",
    "Random Search: Selecci√≥n aleatoria de combinaciones\n",
    "\n",
    "Ventajas de Keras Tuner:\n",
    "\n",
    "üîß Facilidad de uso: API simple y consistente\n",
    "üöÄ Algoritmos avanzados: Hyperband, Bayesian Optimization\n",
    "üìä Integraci√≥n nativa: Funciona perfectamente con Keras/TensorFlow\n",
    "üíæ Persistencia autom√°tica: Guarda resultados y permite reanudar b√∫squedas\n",
    "üìà Visualizaci√≥n: Herramientas integradas para an√°lisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4810c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Instalaci√≥n de Keras Tuner y dependencias\n",
    "!pip install -q keras_tuner\n",
    "!pip install -q seaborn\n",
    "print(\"‚úÖ Instalaci√≥n completada exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Importaci√≥n de librer√≠as esenciales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Librer√≠as de sklearn para datos y preprocesamiento\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuraci√≥n para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configuraci√≥n de matplotlib para mejores gr√°ficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üéØ Librer√≠as importadas correctamente\")\n",
    "print(f\"üìä TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üîß Keras Tuner version: {kt.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54e6bc",
   "metadata": {},
   "source": [
    "üìä Preparaci√≥n y An√°lisis del Dataset\n",
    "Utilizaremos el Breast Cancer Wisconsin Dataset, un dataset cl√°sico para clasificaci√≥n binaria que contiene caracter√≠sticas extra√≠das de im√°genes digitalizadas de masas de tejido mamario.\n",
    "\n",
    "üî¨ Caracter√≠sticas del Dataset\n",
    "Instancias: 569 muestras\n",
    "Features: 30 caracter√≠sticas num√©ricas\n",
    "Clases: Maligno (1) y Benigno (0)\n",
    "Tipo: Problema de clasificaci√≥n binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Carga y exploraci√≥n del dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"üîç AN√ÅLISIS EXPLORATORIO DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìà Forma del dataset: {X.shape}\")\n",
    "print(f\"üéØ Clases: {data.target_names}\")\n",
    "print(f\"üìä Distribuci√≥n de clases: {np.bincount(y)}\")\n",
    "print(f\"üìã Caracter√≠sticas: {len(data.feature_names)}\")\n",
    "\n",
    "# Crear DataFrame para mejor visualizaci√≥n\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"\\nüìã ESTAD√çSTICAS DESCRIPTIVAS:\")\n",
    "print(df.describe().round(2))\n",
    "\n",
    "print(f\"\\nüéØ BALANCE DE CLASES:\")\n",
    "print(f\"Benigno (0): {(y == 1).sum()} ({(y == 1).mean()*100:.1f}%)\")\n",
    "print(f\"Maligno (1): {(y == 0).sum()} ({(y == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c27462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualizaci√≥n del dataset\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Distribuci√≥n de clases\n",
    "axes[0, 0].pie([212, 357], labels=['Maligno', 'Benigno'], autopct='%1.1f%%', colors=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0, 0].set_title('üéØ Distribuci√≥n de Clases')\n",
    "\n",
    "# Histograma de algunas caracter√≠sticas importantes\n",
    "axes[0, 1].hist([df[df['target']==0]['mean radius'], df[df['target']==1]['mean radius']], alpha=0.7, label=['Maligno', 'Benigno'], bins=20)\n",
    "axes[0, 1].set_title('üìè Distribuci√≥n del Radio Medio')\n",
    "axes[0, 1].set_xlabel('Radio Medio')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Correlaci√≥n entre algunas caracter√≠sticas\n",
    "correlation_features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area']\n",
    "corr_matrix = df[correlation_features + ['target']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('üî• Mapa de Correlaci√≥n')\n",
    "\n",
    "# Boxplot de caracter√≠sticas importantes\n",
    "df_melted = df[['mean radius', 'mean texture', 'target']].melt(id_vars=['target'])\n",
    "sns.boxplot(data=df_melted, x='variable', y='value', hue='target', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('üì¶ Distribuci√≥n por Clase')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizaci√≥n del dataset completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35665dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Divisi√≥n y preprocesamiento de datos\n",
    "print(\"üîÑ PREPROCESAMIENTO DE DATOS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Divisi√≥n estratificada del dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìä Conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"üß™ Conjunto de prueba: {X_test.shape}\")\n",
    "\n",
    "# Verificar distribuci√≥n en conjuntos\n",
    "print(f\"\\nüéØ Distribuci√≥n en entrenamiento:\")\n",
    "print(f\" Benigno: {(y_train == 1).sum()} ({(y_train == 1).mean()*100:.1f}%)\")\n",
    "print(f\" Maligno: {(y_train == 0).sum()} ({(y_train == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüéØ Distribuci√≥n en prueba:\")\n",
    "print(f\" Benigno: {(y_test == 1).sum()} ({(y_test == 1).mean()*100:.1f}%)\")\n",
    "print(f\" Maligno: {(y_test == 0).sum()} ({(y_test == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "# Estandarizaci√≥n de caracter√≠sticas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nüìê Estad√≠sticas despu√©s de la estandarizaci√≥n:\")\n",
    "print(f\" Media del conjunto de entrenamiento: {X_train_scaled.mean():.3f}\")\n",
    "print(f\" Desviaci√≥n est√°ndar del entrenamiento: {X_train_scaled.std():.3f}\")\n",
    "\n",
    "# Visualizar el efecto de la estandarizaci√≥n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.hist(X_train[:, 0], bins=30, alpha=0.7, label='Original')\n",
    "ax1.set_title('üìä Antes de Estandarizaci√≥n')\n",
    "ax1.set_xlabel('Valores')\n",
    "ax1.set_ylabel('Frecuencia')\n",
    "ax2.hist(X_train_scaled[:, 0], bins=30, alpha=0.7, label='Estandarizado', color='orange')\n",
    "ax2.set_title('üìä Despu√©s de Estandarizaci√≥n')\n",
    "ax2.set_xlabel('Valores')\n",
    "ax2.set_ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Preprocesamiento completado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72771500",
   "metadata": {},
   "source": [
    "üèóÔ∏è Funci√≥n de Construcci√≥n del Modelo Base\n",
    "Definiremos una funci√≥n que construye modelos con arquitectura variable, permitiendo ajustar m√∫ltiples hiperpar√°metros simult√°neamente.\n",
    "\n",
    "üí° Hiperpar√°metros a Optimizar\n",
    "Arquitectura: N√∫mero de capas ocultas (1-5)\n",
    "Neuronas: Unidades por capa (32-512)\n",
    "Activaci√≥n: Funciones (ReLU, Tanh, Sigmoid)\n",
    "Regularizaci√≥n: L2 regularization (1e-5 to 1e-2)\n",
    "Dropout: Tasa de dropout (0.0-0.5)\n",
    "Optimizador: Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af32788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\" üèóÔ∏è Construye un modelo de red neuronal con hiperpar√°metros variables\n",
    "    \n",
    "    Args:\n",
    "        hp: Objeto HyperParameters de Keras Tuner\n",
    "    \n",
    "    Returns:\n",
    "        model: Modelo compilado de Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # üß± Inicializar modelo secuencial\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # üìè Definir n√∫mero de capas ocultas\n",
    "    num_layers = hp.Int(\n",
    "        name='num_layers',\n",
    "        min_value=1,\n",
    "        max_value=5,\n",
    "        default=2\n",
    "    )\n",
    "    \n",
    "    # üéØ Primera capa (incluye input_shape)\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int(\n",
    "            name='units_0',\n",
    "            min_value=32,\n",
    "            max_value=512,\n",
    "            step=32,\n",
    "            default=128\n",
    "        ),\n",
    "        activation=hp.Choice(\n",
    "            name='activation_0',\n",
    "            values=['relu', 'tanh', 'sigmoid'],\n",
    "            default='relu'\n",
    "        ),\n",
    "        kernel_regularizer=keras.regularizers.l2(\n",
    "            hp.Float(\n",
    "                name='l2_0',\n",
    "                min_value=1e-5,\n",
    "                max_value=1e-2,\n",
    "                sampling='log',\n",
    "                default=1e-4\n",
    "            )\n",
    "        ),\n",
    "        input_shape=(X_train_scaled.shape[1],)\n",
    "    ))\n",
    "    \n",
    "    # ‚ûï Capas ocultas adicionales\n",
    "    for i in range(1, num_layers):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(\n",
    "                name=f'units_{i}',\n",
    "                min_value=32,\n",
    "                max_value=512,\n",
    "                step=32,\n",
    "                default=64\n",
    "            ),\n",
    "            activation=hp.Choice(\n",
    "                name=f'activation_{i}',\n",
    "                values=['relu', 'tanh', 'sigmoid'],\n",
    "                default='relu'\n",
    "            ),\n",
    "            kernel_regularizer=keras.regularizers.l2(\n",
    "                hp.Float(\n",
    "                    name=f'l2_{i}',\n",
    "                    min_value=1e-5,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='log',\n",
    "                    default=1e-4\n",
    "                )\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # üö´ Agregar dropout entre capas\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(\n",
    "                name=f'dropout_{i}',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                step=0.1,\n",
    "                default=0.2\n",
    "            )\n",
    "        ))\n",
    "    \n",
    "    # üéØ Capa de salida para clasificaci√≥n binaria\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # ‚öôÔ∏è Seleccionar optimizador\n",
    "    optimizer_choice = hp.Choice(\n",
    "        name='optimizer',\n",
    "        values=['adam', 'sgd', 'rmsprop'],\n",
    "        default='adam'\n",
    "    )\n",
    "    \n",
    "    # üìê Compilar modelo\n",
    "    model.compile(\n",
    "        optimizer=optimizer_choice,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# üß™ Prueba de la funci√≥n\n",
    "print(\"üß™ PRUEBA DE LA FUNCI√ìN BUILD_MODEL\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Crear un objeto de hiperpar√°metros de prueba\n",
    "test_hp = kt.HyperParameters()\n",
    "test_model = build_model(test_hp)\n",
    "\n",
    "print(\"‚úÖ Funci√≥n build_model creada exitosamente\")\n",
    "print(f\"üìä Modelo de prueba creado con arquitectura:\")\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a16ee2",
   "metadata": {},
   "source": [
    "üöÄ EJERCICIO 1: Investigaci√≥n e Implementaci√≥n de Hyperband\n",
    "üìö Teor√≠a: Algoritmo Hyperband\n",
    "Hyperband es un algoritmo de optimizaci√≥n de hiperpar√°metros basado en el problema de \"multi-armed bandit\" que utiliza early stopping de manera principiada.\n",
    "\n",
    "üéØ Principios Fundamentales\n",
    "Hyperband se basa en el algoritmo Successive Halving:\n",
    "\n",
    "R: Presupuesto m√°ximo de recursos\n",
    "Œ∑: Factor de reducci√≥n (t√≠picamente 3 o 4)\n",
    "r_i: Recursos asignados en la iteraci√≥n i\n",
    "üîÑ Proceso de Optimizaci√≥n\n",
    "Inicializaci√≥n: Se generan n configuraciones aleatorias\n",
    "Evaluaci√≥n: Cada configuraci√≥n se entrena con R/Œ∑^k recursos\n",
    "Selecci√≥n: Se mantienen las mejores Œ∑ configuraciones\n",
    "Iteraci√≥n: Se repite el proceso aumentando los recursos\n",
    "‚ö° Ventajas Principales\n",
    "Eficiencia Computacional: Elimina configuraciones pobres r√°pidamente\n",
    "No requiere conocimiento previo: No necesita configuraci√≥n manual\n",
    "Balanceo autom√°tico: Equilibra exploraci√≥n vs explotaci√≥n\n",
    "Escalabilidad: Funciona bien con espacios grandes de hiperpar√°metros\n",
    "‚ö†Ô∏è Consideraciones Importantes\n",
    "Funciona mejor cuando hay correlaci√≥n entre rendimiento temprano y final\n",
    "Puede no ser √≥ptimo para modelos que requieren muchas √©pocas para converger\n",
    "El factor Œ∑ debe ajustarse seg√∫n el problema espec√≠fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Implementaci√≥n de Hyperband\n",
    "print(\"üöÄ CONFIGURANDO HYPERBAND TUNER\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Configurar Hyperband tuner\n",
    "hyperband_tuner = kt.Hyperband(\n",
    "    hypermodel=build_model,  # Funci√≥n que construye el modelo\n",
    "    objective='val_accuracy',  # M√©trica a optimizar\n",
    "    max_epochs=50,  # N√∫mero m√°ximo de √©pocas\n",
    "    factor=3,  # Factor de reducci√≥n Œ∑\n",
    "    hyperband_iterations=2,  # N√∫mero de iteraciones de Hyperband\n",
    "    directory='hyperband_results',  # Directorio para guardar resultados\n",
    "    project_name='breast_cancer_hyperband',  # Nombre del proyecto\n",
    "    overwrite=True  # Sobrescribir resultados anteriores\n",
    ")\n",
    "\n",
    "# Mostrar informaci√≥n del tuner\n",
    "print(f\"üìä Objetivo de optimizaci√≥n: {hyperband_tuner.objective.name}\")\n",
    "print(f\"üîß Factor de reducci√≥n: {hyperband_tuner.factor}\")\n",
    "print(f\"‚è±Ô∏è √âpocas m√°ximas: {hyperband_tuner.max_epochs}\")\n",
    "print(f\"üîÑ Iteraciones de Hyperband: {hyperband_tuner.hyperband_iterations}\")\n",
    "\n",
    "# Configurar callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Hyperband tuner configurado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb72af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Ejecutar b√∫squeda con Hyperband\n",
    "print(\"üîç EJECUTANDO B√öSQUEDA HYPERBAND\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Ejecutar la b√∫squeda\n",
    "hyperband_tuner.search(\n",
    "    x=X_train_scaled,\n",
    "    y=y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "hyperband_duration = end_time - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Tiempo total de b√∫squeda: {hyperband_duration:.2f} segundos\")\n",
    "print(\"‚úÖ B√∫squeda Hyperband completada exitosamente\")\n",
    "\n",
    "# Obtener los mejores hiperpar√°metros\n",
    "best_hps_hyperband = hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\\nüèÜ MEJORES HIPERPAR√ÅMETROS ENCONTRADOS POR HYPERBAND:\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"üìä N√∫mero de capas: {best_hps_hyperband.get('num_layers')}\")\n",
    "print(f\"‚öôÔ∏è Optimizador: {best_hps_hyperband.get('optimizer')}\")\n",
    "\n",
    "for i in range(best_hps_hyperband.get('num_layers')):\n",
    "    print(f\"üî∏ Capa {i+1}:\")\n",
    "    print(f\" ‚Ä¢ Unidades: {best_hps_hyperband.get(f'units_{i}')}\")\n",
    "    print(f\" ‚Ä¢ Activaci√≥n: {best_hps_hyperband.get(f'activation_{i}')}\")\n",
    "    print(f\" ‚Ä¢ L2 regularization: {best_hps_hyperband.get(f'l2_{i}'):.2e}\")\n",
    "    if i > 0:\n",
    "        print(f\" ‚Ä¢ Dropout: {best_hps_hyperband.get(f'dropout_{i}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5dcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä An√°lisis de resultados de Hyperband\n",
    "print(\"üìä AN√ÅLISIS DE RESULTADOS - HYPERBAND\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Obtener todos los trials\n",
    "hyperband_trials = hyperband_tuner.oracle.get_best_trials(num_trials=10)\n",
    "\n",
    "# Crear visualizaci√≥n de resultados\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Evoluci√≥n de scores\n",
    "trial_ids = [trial.trial_id for trial in hyperband_trials]\n",
    "scores = [trial.score if trial.score is not None else 0 for trial in hyperband_trials]\n",
    "axes[0, 0].plot(trial_ids, scores, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_title('üöÄ Hyperband: Evoluci√≥n de Scores')\n",
    "axes[0, 0].set_xlabel('Trial ID')\n",
    "axes[0, 0].set_ylabel('Validation Accuracy')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_ylim(0.85, 1.0)\n",
    "\n",
    "# 2. Distribuci√≥n de scores\n",
    "axes[0, 1].hist(scores, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 1].axvline(max(scores), color='red', linestyle='--', label=f'Mejor: {max(scores):.4f}')\n",
    "axes[0, 1].set_title('üìä Distribuci√≥n de Accuracy')\n",
    "axes[0, 1].set_xlabel('Validation Accuracy')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. An√°lisis de n√∫mero de capas\n",
    "num_layers_list = []\n",
    "scores_by_layers = []\n",
    "for trial in hyperband_trials:\n",
    "    if trial.score is not None:\n",
    "        num_layers_list.append(trial.hyperparameters.get('num_layers'))\n",
    "        scores_by_layers.append(trial.score)\n",
    "axes[1, 0].scatter(num_layers_list, scores_by_layers, alpha=0.7, s=100, c='orange')\n",
    "axes[1, 0].set_title('üèóÔ∏è N√∫mero de Capas vs Accuracy')\n",
    "axes[1, 0].set_xlabel('N√∫mero de Capas')\n",
    "axes[1, 0].set_ylabel('Validation Accuracy')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xticks(range(1, 6))\n",
    "\n",
    "# 4. An√°lisis de optimizadores\n",
    "optimizers_list = []\n",
    "for trial in hyperband_trials:\n",
    "    if trial.score is not None:\n",
    "        optimizers_list.append(trial.hyperparameters.get('optimizer'))\n",
    "from collections import Counter\n",
    "opt_counts = Counter(optimizers_list)\n",
    "axes[1, 1].bar(opt_counts.keys(), opt_counts.values(), color=['#ff9999', '#66b3ff', '#99ff99'])\n",
    "axes[1, 1].set_title('‚öôÔ∏è Distribuci√≥n de Optimizadores (Top 10)')\n",
    "axes[1, 1].set_ylabel('Frecuencia')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de rendimiento\n",
    "print(f\"\\nüìà ESTAD√çSTICAS DE RENDIMIENTO:\")\n",
    "print(f\" ‚Ä¢ Mejor accuracy: {max(scores):.4f}\")\n",
    "print(f\" ‚Ä¢ Accuracy promedio: {np.mean(scores):.4f}\")\n",
    "print(f\" ‚Ä¢ Desviaci√≥n est√°ndar: {np.std(scores):.4f}\")\n",
    "print(f\" ‚Ä¢ N√∫mero de trials exitosos: {len([s for s in scores if s > 0])}\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è AN√ÅLISIS ARQUITECTURAL:\")\n",
    "layers_performance = {}\n",
    "for layers, score in zip(num_layers_list, scores_by_layers):\n",
    "    if layers not in layers_performance:\n",
    "        layers_performance[layers] = []\n",
    "    layers_performance[layers].append(score)\n",
    "for layers in sorted(layers_performance.keys()):\n",
    "    scores_layer = layers_performance[layers]\n",
    "    print(f\" ‚Ä¢ {layers} capas: Promedio = {np.mean(scores_layer):.4f}, \"\n",
    "          f\"Mejor = {max(scores_layer):.4f} ({len(scores_layer)} trials)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb77e3",
   "metadata": {},
   "source": [
    "üß† EJERCICIO 2: Investigaci√≥n e Implementaci√≥n de Optimizaci√≥n Bayesiana\n",
    "üìö Teor√≠a: Optimizaci√≥n Bayesiana\n",
    "La Optimizaci√≥n Bayesiana es una t√©cnica de optimizaci√≥n global que utiliza modelos probabil√≠sticos para encontrar el √≥ptimo de funciones costosas de evaluar.\n",
    "\n",
    "üßÆ Componentes Fundamentales\n",
    "1. Modelo Sustituto (Gaussian Process)\n",
    "Un Proceso Gaussiano (GP) modela la funci√≥n objetivo desconocida f(x):\n",
    "\n",
    "Œº(x): Funci√≥n media (t√≠picamente 0)\n",
    "k(x, x'): Funci√≥n de covarianza (kernel)\n",
    "2. Funci√≥n de Adquisici√≥n\n",
    "Determina qu√© punto evaluar siguiente balanceando exploraci√≥n vs explotaci√≥n:\n",
    "\n",
    "f‚Å∫: Mejor valor observado hasta ahora\n",
    "Œº(x), œÉ(x): Media y desviaci√≥n est√°ndar del GP\n",
    "Œ¶, œÜ: CDF y PDF de la distribuci√≥n normal est√°ndar\n",
    "üîÑ Proceso Iterativo\n",
    "Inicializaci√≥n: Evaluar algunos puntos aleatorios\n",
    "Ajuste del GP: Entrenar el modelo sustituto\n",
    "Optimizaci√≥n de adquisici√≥n: Encontrar x* que maximiza la funci√≥n de adquisici√≥n\n",
    "Evaluaci√≥n: Evaluar f(x*) y agregar a los datos\n",
    "Repetir: Hasta alcanzar el presupuesto o convergencia\n",
    "‚úÖ Ventajas sobre M√©todos Tradicionales\n",
    "Eficiencia: Requiere menos evaluaciones para encontrar el √≥ptimo\n",
    "Principiada: Usa informaci√≥n de evaluaciones previas de manera √≥ptima\n",
    "Incertidumbre: Cuantifica la confianza en las predicciones\n",
    "Balance autom√°tico: Equilibra exploraci√≥n y explotaci√≥n naturalmente\n",
    "üí° Kernels Comunes en GP\n",
    "RBF (Radial Basis Function): k(x,x') = œÉ¬≤exp(-||x-x'||¬≤/2l¬≤)\n",
    "Mat√©rn: Para funciones menos suaves\n",
    "Linear: Para relaciones lineales\n",
    "Periodic: Para patrones peri√≥dicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ee9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Implementaci√≥n de Optimizaci√≥n Bayesiana\n",
    "print(\"üß† CONFIGURANDO BAYESIAN OPTIMIZATION TUNER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configurar Bayesian Optimization tuner\n",
    "bayesian_tuner = kt.BayesianOptimization(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=25,  # N√∫mero de trials (menor que random search)\n",
    "    num_initial_points=5,  # Puntos de exploraci√≥n inicial\n",
    "    alpha=1e-4,  # Par√°metro de regularizaci√≥n del GP\n",
    "    beta=2.6,  # Par√°metro de exploraci√≥n (UCB)\n",
    "    directory='bayesian_results',\n",
    "    project_name='breast_cancer_bayesian',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "print(f\"üìä Objetivo de optimizaci√≥n: {bayesian_tuner.objective.name}\")\n",
    "print(f\"üî¨ M√°ximo de trials: {bayesian_tuner.max_trials}\")\n",
    "print(f\"üéØ Puntos iniciales: {bayesian_tuner.num_initial_points}\")\n",
    "print(f\"üîß Alpha (regularizaci√≥n): {bayesian_tuner.alpha}\")\n",
    "print(f\"üéõÔ∏è Beta (exploraci√≥n): {bayesian_tuner.beta}\")\n",
    "\n",
    "print(\"‚úÖ Bayesian Optimization tuner configurado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab530acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Ejecutar b√∫squeda con Optimizaci√≥n Bayesiana\n",
    "print(\"üîç EJECUTANDO OPTIMIZACI√ìN BAYESIANA\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Ejecutar la b√∫squeda\n",
    "bayesian_tuner.search(\n",
    "    x=X_train_scaled,\n",
    "    y=y_train,\n",
    "    epochs=40,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "bayesian_duration = end_time - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Tiempo total de b√∫squeda: {bayesian_duration:.2f} segundos\")\n",
    "print(\"‚úÖ Optimizaci√≥n Bayesiana completada exitosamente\")\n",
    "\n",
    "# Obtener los mejores hiperpar√°metros\n",
    "best_hps_bayesian = bayesian_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\\nüèÜ MEJORES HIPERPAR√ÅMETROS - OPTIMIZACI√ìN BAYESIANA:\")\n",
    "print(\"=\" * 58)\n",
    "print(f\"üìä N√∫mero de capas: {best_hps_bayesian.get('num_layers')}\")\n",
    "print(f\"‚öôÔ∏è Optimizador: {best_hps_bayesian.get('optimizer')}\")\n",
    "\n",
    "for i in range(best_hps_bayesian.get('num_layers')):\n",
    "    print(f\"üî∏ Capa {i+1}:\")\n",
    "    print(f\" ‚Ä¢ Unidades: {best_hps_bayesian.get(f'units_{i}')}\")\n",
    "    print(f\" ‚Ä¢ Activaci√≥n: {best_hps_bayesian.get(f'activation_{i}')}\")\n",
    "    print(f\" ‚Ä¢ L2 regularization: {best_hps_bayesian.get(f'l2_{i}'):.2e}\")\n",
    "    if i > 0:\n",
    "        print(f\" ‚Ä¢ Dropout: {best_hps_bayesian.get(f'dropout_{i}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Comparaci√≥n entre Hyperband y Optimizaci√≥n Bayesiana\n",
    "print(\"üìä COMPARACI√ìN DE M√âTODOS DE OPTIMIZACI√ìN\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Obtener trials de ambos m√©todos\n",
    "bayesian_trials = bayesian_tuner.oracle.get_best_trials(num_trials=15)\n",
    "\n",
    "# Preparar datos para comparaci√≥n\n",
    "hyperband_scores = [trial.score for trial in hyperband_trials if trial.score is not None]\n",
    "bayesian_scores = [trial.score for trial in bayesian_trials if trial.score is not None]\n",
    "\n",
    "# Crear visualizaci√≥n comparativa\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Comparaci√≥n de distribuciones\n",
    "axes[0, 0].hist(hyperband_scores, bins=10, alpha=0.7, label='Hyperband', color='lightblue')\n",
    "axes[0, 0].hist(bayesian_scores, bins=10, alpha=0.7, label='Bayesian Opt.', color='lightcoral')\n",
    "axes[0, 0].set_title('üìä Distribuci√≥n de Scores')\n",
    "axes[0, 0].set_xlabel('Validation Accuracy')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box plots comparativo\n",
    "data_comparison = [hyperband_scores, bayesian_scores]\n",
    "axes[0, 1].boxplot(data_comparison, labels=['Hyperband', 'Bayesian Opt.'])\n",
    "axes[0, 1].set_title('üì¶ Comparaci√≥n de Rendimiento')\n",
    "axes[0, 1].set_ylabel('Validation Accuracy')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Evoluci√≥n temporal (simulada)\n",
    "trials_hyperband = list(range(1, len(hyperband_scores) + 1))\n",
    "trials_bayesian = list(range(1, len(bayesian_scores) + 1))\n",
    "axes[0, 2].plot(trials_hyperband, hyperband_scores, 'o-', label='Hyperband', linewidth=2)\n",
    "axes[0, 2].plot(trials_bayesian, bayesian_scores, 's-', label='Bayesian Opt.', linewidth=2)\n",
    "axes[0, 2].set_title('‚è±Ô∏è Evoluci√≥n de Scores')\n",
    "axes[0, 2].set_xlabel('Trial Number')\n",
    "axes[0, 2].set_ylabel('Validation Accuracy')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Estad√≠sticas de rendimiento\n",
    "methods = ['Hyperband', 'Bayesian Opt.']\n",
    "best_scores = [max(hyperband_scores), max(bayesian_scores)]\n",
    "mean_scores = [np.mean(hyperband_scores), np.mean(bayesian_scores)]\n",
    "std_scores = [np.std(hyperband_scores), np.std(bayesian_scores)]\n",
    "x_pos = np.arange(len(methods))\n",
    "axes[1, 0].bar(x_pos - 0.2, best_scores, 0.4, label='Mejor Score', alpha=0.8)\n",
    "axes[1, 0].bar(x_pos + 0.2, mean_scores, 0.4, label='Score Promedio', alpha=0.8)\n",
    "axes[1, 0].set_title('üèÜ Comparaci√≥n de Rendimiento')\n",
    "axes[1, 0].set_ylabel('Validation Accuracy')\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(methods)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Eficiencia temporal\n",
    "durations = [hyperband_duration, bayesian_duration]\n",
    "efficiency = [best_scores[i] / (durations[i] / 60) for i in range(2)]  # Score por minuto\n",
    "axes[1, 1].bar(methods, durations, color=['lightblue', 'lightcoral'], alpha=0.7)\n",
    "axes[1, 1].set_title('‚è±Ô∏è Tiempo de Ejecuci√≥n')\n",
    "axes[1, 1].set_ylabel('Tiempo (segundos)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Eficiencia (Score/Tiempo)\n",
    "axes[1, 2].bar(methods, efficiency, color=['navy', 'darkred'], alpha=0.7)\n",
    "axes[1, 2].set_title('‚ö° Eficiencia (Score/Minuto)')\n",
    "axes[1, 2].set_ylabel('Eficiencia')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir estad√≠sticas detalladas\n",
    "print(f\"\\nüìà ESTAD√çSTICAS COMPARATIVAS:\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"üöÄ HYPERBAND:\")\n",
    "print(f\" ‚Ä¢ Mejor accuracy: {max(hyperband_scores):.4f}\")\n",
    "print(f\" ‚Ä¢ Accuracy promedio: {np.mean(hyperband_scores):.4f} ¬± {np.std(hyperband_scores):.4f}\")\n",
    "print(f\" ‚Ä¢ Tiempo total: {hyperband_duration:.1f} segundos\")\n",
    "print(f\" ‚Ä¢ Trials exitosos: {len(hyperband_scores)}\")\n",
    "print(f\"\\nüß† OPTIMIZACI√ìN BAYESIANA:\")\n",
    "print(f\" ‚Ä¢ Mejor accuracy: {max(bayesian_scores):.4f}\")\n",
    "print(f\" ‚Ä¢ Accuracy promedio: {np.mean(bayesian_scores):.4f} ¬± {np.std(bayesian_scores):.4f}\")\n",
    "print(f\" ‚Ä¢ Tiempo total: {bayesian_duration:.1f} segundos\")\n",
    "print(f\" ‚Ä¢ Trials exitosos: {len(bayesian_scores)}\")\n",
    "print(f\"\\n‚ö° AN√ÅLISIS DE EFICIENCIA:\")\n",
    "print(f\" ‚Ä¢ Hyperband: {efficiency[0]:.6f} score/minuto\")\n",
    "print(f\" ‚Ä¢ Bayesian Opt.: {efficiency[1]:.6f} score/minuto\")\n",
    "winner = \"Hyperband\" if max(hyperband_scores) > max(bayesian_scores) else \"Optimizaci√≥n Bayesiana\"\n",
    "print(f\"\\nüèÜ Ganador en accuracy: {winner}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc153a7",
   "metadata": {},
   "source": [
    "üìà EJERCICIO 3: Visualizaci√≥n Avanzada de Resultados\n",
    "La visualizaci√≥n de resultados es crucial para entender el comportamiento de los algoritmos de optimizaci√≥n y tomar decisiones informadas sobre la selecci√≥n de hiperpar√°metros.\n",
    "\n",
    "üé® Importancia de la Visualizaci√≥n en Optimizaci√≥n\n",
    "Convergencia: Observar c√≥mo mejoran los algoritmos con el tiempo\n",
    "Exploraci√≥n vs Explotaci√≥n: Entender el balance de los algoritmos\n",
    "Identificaci√≥n de patrones: Detectar relaciones entre hiperpar√°metros\n",
    "Validaci√≥n de resultados: Confirmar la calidad de la optimizaci√≥n\n",
    "Comunicaci√≥n: Presentar resultados de manera clara"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
