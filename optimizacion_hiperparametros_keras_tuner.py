#!/usr/bin/env python
# coding: utf-8

# ğŸ“š IntroducciÃ³n TeÃ³rica
# Â¿QuÃ© son los HiperparÃ¡metros?
# Los hiperparÃ¡metros son configuraciones que definen la arquitectura y el comportamiento de un modelo de aprendizaje automÃ¡tico, pero que no se aprenden durante el entrenamiento. A diferencia de los parÃ¡metros (como pesos y sesgos), los hiperparÃ¡metros deben ser establecidos antes del entrenamiento.
# 
# ğŸ” Diferencias Clave: ParÃ¡metros vs HiperparÃ¡metros
# Aspecto	ParÃ¡metros	HiperparÃ¡metros
# DefiniciÃ³n	Variables aprendidas por el modelo	Configuraciones establecidas antes del entrenamiento
# Ejemplos	Pesos, sesgos	Learning rate, nÃºmero de capas, dropout rate
# OptimizaciÃ³n	Gradient descent, backpropagation	Grid search, random search, Bayesian optimization
# ModificaciÃ³n	Durante el entrenamiento	Antes del entrenamiento
# 
# âš ï¸ Importancia de la OptimizaciÃ³n de HiperparÃ¡metros
# Rendimiento: Puede mejorar la precisiÃ³n del modelo en 5-15%
# GeneralizaciÃ³n: Reduce overfitting y mejora la capacidad de generalizaciÃ³n
# Eficiencia: Optimiza el tiempo de entrenamiento y los recursos computacionales
# Robustez: Hace el modelo mÃ¡s estable ante variaciones en los datos
# 
# ğŸ› ï¸ MÃ©todos Tradicionales vs Keras Tuner
# MÃ©todos Tradicionales:
# 
# Manual: Ajuste basado en experiencia e intuiciÃ³n
# Grid Search: BÃºsqueda exhaustiva en una grilla predefinida
# Random Search: SelecciÃ³n aleatoria de combinaciones
# 
# Ventajas de Keras Tuner:
# 
# ğŸ”§ Facilidad de uso: API simple y consistente
# ğŸš€ Algoritmos avanzados: Hyperband, Bayesian Optimization
# ğŸ“Š IntegraciÃ³n nativa: Funciona perfectamente con Keras/TensorFlow
# ğŸ’¾ Persistencia automÃ¡tica: Guarda resultados y permite reanudar bÃºsquedas
# ğŸ“ˆ VisualizaciÃ³n: Herramientas integradas para anÃ¡lisis de resultados

# In[ ]:


# ğŸ“¦ InstalaciÃ³n de Keras Tuner y dependencias
# get_ipython().system('pip install -q keras_tuner')
# get_ipython().system('pip install -q seaborn')
print("âœ… InstalaciÃ³n completada exitosamente!")


# In[ ]:


# ğŸ“š ImportaciÃ³n de librerÃ­as esenciales
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from keras import layers
import keras_tuner as kt

# LibrerÃ­as de sklearn para datos y preprocesamiento
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix

# ConfiguraciÃ³n para reproducibilidad
np.random.seed(42)
tf.random.set_seed(42)

# ConfiguraciÃ³n de matplotlib para mejores grÃ¡ficos
plt.style.use('default')
sns.set_palette("husl")

print("ğŸ¯ LibrerÃ­as importadas correctamente")
print(f"ğŸ“Š TensorFlow version: {tf.__version__}")
print(f"ğŸ”§ Keras Tuner version: {kt.__version__}")


# ğŸ“Š PreparaciÃ³n y AnÃ¡lisis del Dataset
# Utilizaremos el Breast Cancer Wisconsin Dataset, un dataset clÃ¡sico para clasificaciÃ³n binaria que contiene caracterÃ­sticas extraÃ­das de imÃ¡genes digitalizadas de masas de tejido mamario.
# 
# ğŸ”¬ CaracterÃ­sticas del Dataset
# Instancias: 569 muestras
# Features: 30 caracterÃ­sticas numÃ©ricas
# Clases: Maligno (1) y Benigno (0)
# Tipo: Problema de clasificaciÃ³n binaria

# In[ ]:


# ğŸ“¥ Carga y exploraciÃ³n del dataset
data = load_breast_cancer()
X = data.data
y = data.target

print("ğŸ” ANÃLISIS EXPLORATORIO DEL DATASET")
print("=" * 50)
print(f"ğŸ“ˆ Forma del dataset: {X.shape}")
print(f"ğŸ¯ Clases: {data.target_names}")
print(f"ğŸ“Š DistribuciÃ³n de clases: {np.bincount(y)}")
print(f"ğŸ“‹ CaracterÃ­sticas: {len(data.feature_names)}")

# Crear DataFrame para mejor visualizaciÃ³n
df = pd.DataFrame(X, columns=data.feature_names)
df['target'] = y

print("\nğŸ“‹ ESTADÃSTICAS DESCRIPTIVAS:")
print(df.describe().round(2))

print(f"\nğŸ¯ BALANCE DE CLASES:")
print(f"Benigno (0): {(y == 1).sum()} ({(y == 1).mean()*100:.1f}%)")
print(f"Maligno (1): {(y == 0).sum()} ({(y == 0).mean()*100:.1f}%)")


# In[ ]:


# ğŸ“Š VisualizaciÃ³n del dataset
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# DistribuciÃ³n de clases
axes[0, 0].pie([212, 357], labels=['Maligno', 'Benigno'], autopct='%1.1f%%', colors=['#ff6b6b', '#4ecdc4'])
axes[0, 0].set_title('ğŸ¯ DistribuciÃ³n de Clases')

# Histograma de algunas caracterÃ­sticas importantes
axes[0, 1].hist([df[df['target']==0]['mean radius'], df[df['target']==1]['mean radius']], alpha=0.7, label=['Maligno', 'Benigno'], bins=20)
axes[0, 1].set_title('ğŸ“ DistribuciÃ³n del Radio Medio')
axes[0, 1].set_xlabel('Radio Medio')
axes[0, 1].legend()

# CorrelaciÃ³n entre algunas caracterÃ­sticas
correlation_features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area']
corr_matrix = df[correlation_features + ['target']].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])
axes[1, 0].set_title('ğŸ”¥ Mapa de CorrelaciÃ³n')

# Boxplot de caracterÃ­sticas importantes
df_melted = df[['mean radius', 'mean texture', 'target']].melt(id_vars=['target'])
sns.boxplot(data=df_melted, x='variable', y='value', hue='target', ax=axes[1, 1])
axes[1, 1].set_title('ğŸ“¦ DistribuciÃ³n por Clase')
axes[1, 1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

print("âœ… VisualizaciÃ³n del dataset completada")


# In[ ]:


# ğŸ”§ DivisiÃ³n y preprocesamiento de datos
print("ğŸ”„ PREPROCESAMIENTO DE DATOS")
print("=" * 40)

# DivisiÃ³n estratificada del dataset
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print(f"ğŸ“Š Conjunto de entrenamiento: {X_train.shape}")
print(f"ğŸ§ª Conjunto de prueba: {X_test.shape}")

# Verificar distribuciÃ³n en conjuntos
print(f"\nğŸ¯ DistribuciÃ³n en entrenamiento:")
print(f" Benigno: {(y_train == 1).sum()} ({(y_train == 1).mean()*100:.1f}%)")
print(f" Maligno: {(y_train == 0).sum()} ({(y_train == 0).mean()*100:.1f}%)")

print(f"\nğŸ¯ DistribuciÃ³n en prueba:")
print(f" Benigno: {(y_test == 1).sum()} ({(y_test == 1).mean()*100:.1f}%)")
print(f" Maligno: {(y_test == 0).sum()} ({(y_test == 0).mean()*100:.1f}%)")

# EstandarizaciÃ³n de caracterÃ­sticas
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"\nğŸ“ EstadÃ­sticas despuÃ©s de la estandarizaciÃ³n:")
print(f" Media del conjunto de entrenamiento: {X_train_scaled.mean():.3f}")
print(f" DesviaciÃ³n estÃ¡ndar del entrenamiento: {X_train_scaled.std():.3f}")

# Visualizar el efecto de la estandarizaciÃ³n
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
ax1.hist(X_train[:, 0], bins=30, alpha=0.7, label='Original')
ax1.set_title('ğŸ“Š Antes de EstandarizaciÃ³n')
ax1.set_xlabel('Valores')
ax1.set_ylabel('Frecuencia')
ax2.hist(X_train_scaled[:, 0], bins=30, alpha=0.7, label='Estandarizado', color='orange')
ax2.set_title('ğŸ“Š DespuÃ©s de EstandarizaciÃ³n')
ax2.set_xlabel('Valores')
ax2.set_ylabel('Frecuencia')
plt.tight_layout()
plt.show()

print("âœ… Preprocesamiento completado exitosamente")


# ğŸ—ï¸ FunciÃ³n de ConstrucciÃ³n del Modelo Base
# Definiremos una funciÃ³n que construye modelos con arquitectura variable, permitiendo ajustar mÃºltiples hiperparÃ¡metros simultÃ¡neamente.
# 
# ğŸ’¡ HiperparÃ¡metros a Optimizar
# Arquitectura: NÃºmero de capas ocultas (1-5)
# Neuronas: Unidades por capa (32-512)
# ActivaciÃ³n: Funciones (ReLU, Tanh, Sigmoid)
# RegularizaciÃ³n: L2 regularization (1e-5 to 1e-2)
# Dropout: Tasa de dropout (0.0-0.5)
# Optimizador: Adam, SGD, RMSprop

# In[ ]:


def build_model(hp):
    """ ğŸ—ï¸ Construye un modelo de red neuronal con hiperparÃ¡metros variables

    Args:
        hp: Objeto HyperParameters de Keras Tuner

    Returns:
        model: Modelo compilado de Keras
    """

    # ğŸ§± Inicializar modelo secuencial
    model = keras.Sequential()

    # ğŸ“ Definir nÃºmero de capas ocultas
    num_layers = hp.Int(
        name='num_layers',
        min_value=1,
        max_value=5,
        default=2
    )

    # ğŸ¯ Primera capa (incluye input_shape)
    model.add(layers.Dense(
        units=hp.Int(
            name='units_0',
            min_value=32,
            max_value=512,
            step=32,
            default=128
        ),
        activation=hp.Choice(
            name='activation_0',
            values=['relu', 'tanh', 'sigmoid'],
            default='relu'
        ),
        kernel_regularizer=keras.regularizers.l2(
            hp.Float(
                name='l2_0',
                min_value=1e-5,
                max_value=1e-2,
                sampling='log',
                default=1e-4
            )
        ),
        input_shape=(X_train_scaled.shape[1],)
    ))

    # â• Capas ocultas adicionales
    for i in range(1, num_layers):
        model.add(layers.Dense(
            units=hp.Int(
                name=f'units_{i}',
                min_value=32,
                max_value=512,
                step=32,
                default=64
            ),
            activation=hp.Choice(
                name=f'activation_{i}',
                values=['relu', 'tanh', 'sigmoid'],
                default='relu'
            ),
            kernel_regularizer=keras.regularizers.l2(
                hp.Float(
                    name=f'l2_{i}',
                    min_value=1e-5,
                    max_value=1e-2,
                    sampling='log',
                    default=1e-4
                )
            )
        ))

        # ğŸš« Agregar dropout entre capas
        model.add(layers.Dropout(
            rate=hp.Float(
                name=f'dropout_{i}',
                min_value=0.0,
                max_value=0.5,
                step=0.1,
                default=0.2
            )
        ))

    # ğŸ¯ Capa de salida para clasificaciÃ³n binaria
    model.add(layers.Dense(1, activation='sigmoid'))

    # âš™ï¸ Seleccionar optimizador
    optimizer_choice = hp.Choice(
        name='optimizer',
        values=['adam', 'sgd', 'rmsprop'],
        default='adam'
    )

    # ğŸ“ Compilar modelo
    model.compile(
        optimizer=optimizer_choice,
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )

    return model

# ğŸ§ª Prueba de la funciÃ³n
print("ğŸ§ª PRUEBA DE LA FUNCIÃ“N BUILD_MODEL")
print("=" * 40)

# Crear un objeto de hiperparÃ¡metros de prueba
test_hp = kt.HyperParameters()
test_model = build_model(test_hp)

print("âœ… FunciÃ³n build_model creada exitosamente")
print(f"ğŸ“Š Modelo de prueba creado con arquitectura:")
test_model.summary()


# ğŸš€ EJERCICIO 1: InvestigaciÃ³n e ImplementaciÃ³n de Hyperband
# ğŸ“š TeorÃ­a: Algoritmo Hyperband
# Hyperband es un algoritmo de optimizaciÃ³n de hiperparÃ¡metros basado en el problema de "multi-armed bandit" que utiliza early stopping de manera principiada.
# 
# ğŸ¯ Principios Fundamentales
# Hyperband se basa en el algoritmo Successive Halving:
# 
# R: Presupuesto mÃ¡ximo de recursos
# Î·: Factor de reducciÃ³n (tÃ­picamente 3 o 4)
# r_i: Recursos asignados en la iteraciÃ³n i
# ğŸ”„ Proceso de OptimizaciÃ³n
# InicializaciÃ³n: Se generan n configuraciones aleatorias
# EvaluaciÃ³n: Cada configuraciÃ³n se entrena con R/Î·^k recursos
# SelecciÃ³n: Se mantienen las mejores Î· configuraciones
# IteraciÃ³n: Se repite el proceso aumentando los recursos
# âš¡ Ventajas Principales
# Eficiencia Computacional: Elimina configuraciones pobres rÃ¡pidamente
# No requiere conocimiento previo: No necesita configuraciÃ³n manual
# Balanceo automÃ¡tico: Equilibra exploraciÃ³n vs explotaciÃ³n
# Escalabilidad: Funciona bien con espacios grandes de hiperparÃ¡metros
# âš ï¸ Consideraciones Importantes
# Funciona mejor cuando hay correlaciÃ³n entre rendimiento temprano y final
# Puede no ser Ã³ptimo para modelos que requieren muchas Ã©pocas para converger
# El factor Î· debe ajustarse segÃºn el problema especÃ­fico

# In[ ]:


# ğŸš€ ImplementaciÃ³n de Hyperband
print("ğŸš€ CONFIGURANDO HYPERBAND TUNER")
print("=" * 45)

# Configurar Hyperband tuner
hyperband_tuner = kt.Hyperband(
    hypermodel=build_model,  # FunciÃ³n que construye el modelo
    objective='val_accuracy',  # MÃ©trica a optimizar
    max_epochs=50,  # NÃºmero mÃ¡ximo de Ã©pocas
    factor=3,  # Factor de reducciÃ³n Î·
    hyperband_iterations=2,  # NÃºmero de iteraciones de Hyperband
    directory='hyperband_results',  # Directorio para guardar resultados
    project_name='breast_cancer_hyperband',  # Nombre del proyecto
    overwrite=True  # Sobrescribir resultados anteriores
)

# Mostrar informaciÃ³n del tuner
print(f"ğŸ“Š Objetivo de optimizaciÃ³n: {hyperband_tuner.objective.name}")
print(f"ğŸ”§ Factor de reducciÃ³n: {hyperband_tuner.factor}")
print(f"â±ï¸ Ã‰pocas mÃ¡ximas: {hyperband_tuner.max_epochs}")
print(f"ğŸ”„ Iteraciones de Hyperband: {hyperband_tuner.hyperband_iterations}")

# Configurar callbacks
callbacks = [
    tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-6
    )
]

print("âœ… Hyperband tuner configurado exitosamente")


# In[ ]:


# ğŸ” Ejecutar bÃºsqueda con Hyperband
print("ğŸ” EJECUTANDO BÃšSQUEDA HYPERBAND")
print("=" * 40)

import time
start_time = time.time()

# Ejecutar la bÃºsqueda
hyperband_tuner.search(
    x=X_train_scaled,
    y=y_train,
    epochs=50,
    validation_split=0.2,
    callbacks=callbacks,
    verbose=1,
    batch_size=32
)

end_time = time.time()
hyperband_duration = end_time - start_time

print(f"\nâ±ï¸ Tiempo total de bÃºsqueda: {hyperband_duration:.2f} segundos")
print("âœ… BÃºsqueda Hyperband completada exitosamente")

# Obtener los mejores hiperparÃ¡metros
best_hps_hyperband = hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"\nğŸ† MEJORES HIPERPARÃMETROS ENCONTRADOS POR HYPERBAND:")
print("=" * 55)
print(f"ğŸ“Š NÃºmero de capas: {best_hps_hyperband.get('num_layers')}")
print(f"âš™ï¸ Optimizador: {best_hps_hyperband.get('optimizer')}")

for i in range(best_hps_hyperband.get('num_layers')):
    print(f"ğŸ”¸ Capa {i+1}:")
    print(f" â€¢ Unidades: {best_hps_hyperband.get(f'units_{i}')}")
    print(f" â€¢ ActivaciÃ³n: {best_hps_hyperband.get(f'activation_{i}')}")
    print(f" â€¢ L2 regularization: {best_hps_hyperband.get(f'l2_{i}'):.2e}")
    if i > 0:
        print(f" â€¢ Dropout: {best_hps_hyperband.get(f'dropout_{i}')}")


# In[ ]:


# ğŸ“Š AnÃ¡lisis de resultados de Hyperband
print("ğŸ“Š ANÃLISIS DE RESULTADOS - HYPERBAND")
print("=" * 42)

# Obtener todos los trials
hyperband_trials = hyperband_tuner.oracle.get_best_trials(num_trials=10)

# Crear visualizaciÃ³n de resultados
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. EvoluciÃ³n de scores
trial_ids = [trial.trial_id for trial in hyperband_trials]
scores = [trial.score if trial.score is not None else 0 for trial in hyperband_trials]
axes[0, 0].plot(trial_ids, scores, 'bo-', linewidth=2, markersize=8)
axes[0, 0].set_title('ğŸš€ Hyperband: EvoluciÃ³n de Scores')
axes[0, 0].set_xlabel('Trial ID')
axes[0, 0].set_ylabel('Validation Accuracy')
axes[0, 0].grid(True, alpha=0.3)
axes[0, 0].set_ylim(0.85, 1.0)

# 2. DistribuciÃ³n de scores
axes[0, 1].hist(scores, bins=15, alpha=0.7, color='skyblue', edgecolor='black')
axes[0, 1].axvline(max(scores), color='red', linestyle='--', label=f'Mejor: {max(scores):.4f}')
axes[0, 1].set_title('ğŸ“Š DistribuciÃ³n de Accuracy')
axes[0, 1].set_xlabel('Validation Accuracy')
axes[0, 1].set_ylabel('Frecuencia')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# 3. AnÃ¡lisis de nÃºmero de capas
num_layers_list = []
scores_by_layers = []
for trial in hyperband_trials:
    if trial.score is not None:
        num_layers_list.append(trial.hyperparameters.get('num_layers'))
        scores_by_layers.append(trial.score)
axes[1, 0].scatter(num_layers_list, scores_by_layers, alpha=0.7, s=100, c='orange')
axes[1, 0].set_title('ğŸ—ï¸ NÃºmero de Capas vs Accuracy')
axes[1, 0].set_xlabel('NÃºmero de Capas')
axes[1, 0].set_ylabel('Validation Accuracy')
axes[1, 0].grid(True, alpha=0.3)
axes[1, 0].set_xticks(range(1, 6))

# 4. AnÃ¡lisis de optimizadores
optimizers_list = []
for trial in hyperband_trials:
    if trial.score is not None:
        optimizers_list.append(trial.hyperparameters.get('optimizer'))
from collections import Counter
opt_counts = Counter(optimizers_list)
axes[1, 1].bar(opt_counts.keys(), opt_counts.values(), color=['#ff9999', '#66b3ff', '#99ff99'])
axes[1, 1].set_title('âš™ï¸ DistribuciÃ³n de Optimizadores (Top 10)')
axes[1, 1].set_ylabel('Frecuencia')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# EstadÃ­sticas de rendimiento
print(f"\nğŸ“ˆ ESTADÃSTICAS DE RENDIMIENTO:")
print(f" â€¢ Mejor accuracy: {max(scores):.4f}")
print(f" â€¢ Accuracy promedio: {np.mean(scores):.4f}")
print(f" â€¢ DesviaciÃ³n estÃ¡ndar: {np.std(scores):.4f}")
print(f" â€¢ NÃºmero de trials exitosos: {len([s for s in scores if s > 0])}")

print(f"\nğŸ—ï¸ ANÃLISIS ARQUITECTURAL:")
layers_performance = {}
for layers, score in zip(num_layers_list, scores_by_layers):
    if layers not in layers_performance:
        layers_performance[layers] = []
    layers_performance[layers].append(score)
for layers in sorted(layers_performance.keys()):
    scores_layer = layers_performance[layers]
    print(f" â€¢ {layers} capas: Promedio = {np.mean(scores_layer):.4f}, "
          f"Mejor = {max(scores_layer):.4f} ({len(scores_layer)} trials)")


# ğŸ§  EJERCICIO 2: InvestigaciÃ³n e ImplementaciÃ³n de OptimizaciÃ³n Bayesiana
# ğŸ“š TeorÃ­a: OptimizaciÃ³n Bayesiana
# La OptimizaciÃ³n Bayesiana es una tÃ©cnica de optimizaciÃ³n global que utiliza modelos probabilÃ­sticos para encontrar el Ã³ptimo de funciones costosas de evaluar.
# 
# ğŸ§® Componentes Fundamentales
# 1. Modelo Sustituto (Gaussian Process)
# Un Proceso Gaussiano (GP) modela la funciÃ³n objetivo desconocida f(x):
# 
# Î¼(x): FunciÃ³n media (tÃ­picamente 0)
# k(x, x'): FunciÃ³n de covarianza (kernel)
# 2. FunciÃ³n de AdquisiciÃ³n
# Determina quÃ© punto evaluar siguiente balanceando exploraciÃ³n vs explotaciÃ³n:
# 
# fâº: Mejor valor observado hasta ahora
# Î¼(x), Ïƒ(x): Media y desviaciÃ³n estÃ¡ndar del GP
# Î¦, Ï†: CDF y PDF de la distribuciÃ³n normal estÃ¡ndar
# ğŸ”„ Proceso Iterativo
# InicializaciÃ³n: Evaluar algunos puntos aleatorios
# Ajuste del GP: Entrenar el modelo sustituto
# OptimizaciÃ³n de adquisiciÃ³n: Encontrar x* que maximiza la funciÃ³n de adquisiciÃ³n
# EvaluaciÃ³n: Evaluar f(x*) y agregar a los datos
# Repetir: Hasta alcanzar el presupuesto o convergencia
# âœ… Ventajas sobre MÃ©todos Tradicionales
# Eficiencia: Requiere menos evaluaciones para encontrar el Ã³ptimo
# Principiada: Usa informaciÃ³n de evaluaciones previas de manera Ã³ptima
# Incertidumbre: Cuantifica la confianza en las predicciones
# Balance automÃ¡tico: Equilibra exploraciÃ³n y explotaciÃ³n naturalmente
# ğŸ’¡ Kernels Comunes en GP
# RBF (Radial Basis Function): k(x,x') = ÏƒÂ²exp(-||x-x'||Â²/2lÂ²)
# MatÃ©rn: Para funciones menos suaves
# Linear: Para relaciones lineales
# Periodic: Para patrones periÃ³dicos

# In[ ]:


# ğŸ§  ImplementaciÃ³n de OptimizaciÃ³n Bayesiana
print("ğŸ§  CONFIGURANDO BAYESIAN OPTIMIZATION TUNER")
print("=" * 50)

# Configurar Bayesian Optimization tuner
bayesian_tuner = kt.BayesianOptimization(
    hypermodel=build_model,
    objective='val_accuracy',
    max_trials=25,  # NÃºmero de trials (menor que random search)
    num_initial_points=5,  # Puntos de exploraciÃ³n inicial
    alpha=1e-4,  # ParÃ¡metro de regularizaciÃ³n del GP
    beta=2.6,  # ParÃ¡metro de exploraciÃ³n (UCB)
    directory='bayesian_results',
    project_name='breast_cancer_bayesian',
    overwrite=True
)

print(f"ğŸ“Š Objetivo de optimizaciÃ³n: {bayesian_tuner.objective.name}")
print(f"ğŸ”¬ MÃ¡ximo de trials: {bayesian_tuner.max_trials}")
print(f"ğŸ¯ Puntos iniciales: {bayesian_tuner.num_initial_points}")
print(f"ğŸ”§ Alpha (regularizaciÃ³n): {bayesian_tuner.alpha}")
print(f"ğŸ›ï¸ Beta (exploraciÃ³n): {bayesian_tuner.beta}")

print("âœ… Bayesian Optimization tuner configurado exitosamente")


# In[ ]:


# ğŸ” Ejecutar bÃºsqueda con OptimizaciÃ³n Bayesiana
print("ğŸ” EJECUTANDO OPTIMIZACIÃ“N BAYESIANA")
print("=" * 42)

import time
start_time = time.time()

# Ejecutar la bÃºsqueda
bayesian_tuner.search(
    x=X_train_scaled,
    y=y_train,
    epochs=40,
    validation_split=0.2,
    callbacks=callbacks,
    verbose=1,
    batch_size=32
)

end_time = time.time()
bayesian_duration = end_time - start_time

print(f"\nâ±ï¸ Tiempo total de bÃºsqueda: {bayesian_duration:.2f} segundos")
print("âœ… OptimizaciÃ³n Bayesiana completada exitosamente")

# Obtener los mejores hiperparÃ¡metros
best_hps_bayesian = bayesian_tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"\nğŸ† MEJORES HIPERPARÃMETROS - OPTIMIZACIÃ“N BAYESIANA:")
print("=" * 58)
print(f"ğŸ“Š NÃºmero de capas: {best_hps_bayesian.get('num_layers')}")
print(f"âš™ï¸ Optimizador: {best_hps_bayesian.get('optimizer')}")

for i in range(best_hps_bayesian.get('num_layers')):
    print(f"ğŸ”¸ Capa {i+1}:")
    print(f" â€¢ Unidades: {best_hps_bayesian.get(f'units_{i}')}")
    print(f" â€¢ ActivaciÃ³n: {best_hps_bayesian.get(f'activation_{i}')}")
    print(f" â€¢ L2 regularization: {best_hps_bayesian.get(f'l2_{i}'):.2e}")
    if i > 0:
        print(f" â€¢ Dropout: {best_hps_bayesian.get(f'dropout_{i}')}")


# In[ ]:


# ğŸ“Š ComparaciÃ³n entre Hyperband y OptimizaciÃ³n Bayesiana
print("ğŸ“Š COMPARACIÃ“N DE MÃ‰TODOS DE OPTIMIZACIÃ“N")
print("=" * 45)

# Obtener trials de ambos mÃ©todos
bayesian_trials = bayesian_tuner.oracle.get_best_trials(num_trials=15)

# Preparar datos para comparaciÃ³n
hyperband_scores = [trial.score for trial in hyperband_trials if trial.score is not None]
bayesian_scores = [trial.score for trial in bayesian_trials if trial.score is not None]

# Crear visualizaciÃ³n comparativa
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# 1. ComparaciÃ³n de distribuciones
axes[0, 0].hist(hyperband_scores, bins=10, alpha=0.7, label='Hyperband', color='lightblue')
axes[0, 0].hist(bayesian_scores, bins=10, alpha=0.7, label='Bayesian Opt.', color='lightcoral')
axes[0, 0].set_title('ğŸ“Š DistribuciÃ³n de Scores')
axes[0, 0].set_xlabel('Validation Accuracy')
axes[0, 0].set_ylabel('Frecuencia')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. Box plots comparativo
data_comparison = [hyperband_scores, bayesian_scores]
axes[0, 1].boxplot(data_comparison, labels=['Hyperband', 'Bayesian Opt.'])
axes[0, 1].set_title('ğŸ“¦ ComparaciÃ³n de Rendimiento')
axes[0, 1].set_ylabel('Validation Accuracy')
axes[0, 1].grid(True, alpha=0.3)

# 3. EvoluciÃ³n temporal (simulada)
trials_hyperband = list(range(1, len(hyperband_scores) + 1))
trials_bayesian = list(range(1, len(bayesian_scores) + 1))
axes[0, 2].plot(trials_hyperband, hyperband_scores, 'o-', label='Hyperband', linewidth=2)
axes[0, 2].plot(trials_bayesian, bayesian_scores, 's-', label='Bayesian Opt.', linewidth=2)
axes[0, 2].set_title('â±ï¸ EvoluciÃ³n de Scores')
axes[0, 2].set_xlabel('Trial Number')
axes[0, 2].set_ylabel('Validation Accuracy')
axes[0, 2].legend()
axes[0, 2].grid(True, alpha=0.3)

# 4. EstadÃ­sticas de rendimiento
methods = ['Hyperband', 'Bayesian Opt.']
best_scores = [max(hyperband_scores), max(bayesian_scores)]
mean_scores = [np.mean(hyperband_scores), np.mean(bayesian_scores)]
std_scores = [np.std(hyperband_scores), np.std(bayesian_scores)]
x_pos = np.arange(len(methods))
axes[1, 0].bar(x_pos - 0.2, best_scores, 0.4, label='Mejor Score', alpha=0.8)
axes[1, 0].bar(x_pos + 0.2, mean_scores, 0.4, label='Score Promedio', alpha=0.8)
axes[1, 0].set_title('ğŸ† ComparaciÃ³n de Rendimiento')
axes[1, 0].set_ylabel('Validation Accuracy')
axes[1, 0].set_xticks(x_pos)
axes[1, 0].set_xticklabels(methods)
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# 5. Eficiencia temporal
durations = [hyperband_duration, bayesian_duration]
efficiency = [best_scores[i] / (durations[i] / 60) for i in range(2)]  # Score por minuto
axes[1, 1].bar(methods, durations, color=['lightblue', 'lightcoral'], alpha=0.7)
axes[1, 1].set_title('â±ï¸ Tiempo de EjecuciÃ³n')
axes[1, 1].set_ylabel('Tiempo (segundos)')
axes[1, 1].grid(True, alpha=0.3)

# 6. Eficiencia (Score/Tiempo)
axes[1, 2].bar(methods, efficiency, color=['navy', 'darkred'], alpha=0.7)
axes[1, 2].set_title('âš¡ Eficiencia (Score/Minuto)')
axes[1, 2].set_ylabel('Eficiencia')
axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Imprimir estadÃ­sticas detalladas
print(f"\nğŸ“ˆ ESTADÃSTICAS COMPARATIVAS:")
print("=" * 35)
print(f"ğŸš€ HYPERBAND:")
print(f" â€¢ Mejor accuracy: {max(hyperband_scores):.4f}")
print(f" â€¢ Accuracy promedio: {np.mean(hyperband_scores):.4f} Â± {np.std(hyperband_scores):.4f}")
print(f" â€¢ Tiempo total: {hyperband_duration:.1f} segundos")
print(f" â€¢ Trials exitosos: {len(hyperband_scores)}")
print(f"\nğŸ§  OPTIMIZACIÃ“N BAYESIANA:")
print(f" â€¢ Mejor accuracy: {max(bayesian_scores):.4f}")
print(f" â€¢ Accuracy promedio: {np.mean(bayesian_scores):.4f} Â± {np.std(bayesian_scores):.4f}")
print(f" â€¢ Tiempo total: {bayesian_duration:.1f} segundos")
print(f" â€¢ Trials exitosos: {len(bayesian_scores)}")
print(f"\nâš¡ ANÃLISIS DE EFICIENCIA:")
print(f" â€¢ Hyperband: {efficiency[0]:.6f} score/minuto")
print(f" â€¢ Bayesian Opt.: {efficiency[1]:.6f} score/minuto")
winner = "Hyperband" if max(hyperband_scores) > max(bayesian_scores) else "OptimizaciÃ³n Bayesiana"
print(f"\nğŸ† Ganador en accuracy: {winner}")


# ğŸ“ˆ EJERCICIO 3: VisualizaciÃ³n Avanzada de Resultados
# La visualizaciÃ³n de resultados es crucial para entender el comportamiento de los algoritmos de optimizaciÃ³n y tomar decisiones informadas sobre la selecciÃ³n de hiperparÃ¡metros.
# 
# ğŸ¨ Importancia de la VisualizaciÃ³n en OptimizaciÃ³n
# Convergencia: Observar cÃ³mo mejoran los algoritmos con el tiempo
# ExploraciÃ³n vs ExplotaciÃ³n: Entender el balance de los algoritmos
# IdentificaciÃ³n de patrones: Detectar relaciones entre hiperparÃ¡metros
# ValidaciÃ³n de resultados: Confirmar la calidad de la optimizaciÃ³n
# ComunicaciÃ³n: Presentar resultados de manera clara
